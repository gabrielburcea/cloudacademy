{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287c3318",
   "metadata": {},
   "source": [
    "## Activation Function \n",
    "\n",
    " * non-linear functions applied when passing the output of the layer to the next layer or to the function \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca13d0",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "   * can be easily implemented in python as a function that returns 1 of the 1 + of the exponential of x\n",
    "   * smothly maps all of the real axes onto the interval 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc65f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6efb7",
   "metadata": {},
   "source": [
    "###Â Step function obtains the similar effects for:\n",
    " * for very large positive and very large negatives of x \n",
    " * it does with very sharp discontinuous transition at x = 0 \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    return x > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d1130",
   "metadata": {},
   "source": [
    "Examples: \n",
    "\n",
    "$Tanh$\n",
    "* $np.tanh(x)$\n",
    "* hyperbolic tangent $tanh$ - similar to sigmoid - bounded and smoothly varying \n",
    "* since in varies between -1 and 1 it penalises with negative weight values of x that are negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd709c52",
   "metadata": {},
   "source": [
    "$RELU$\n",
    "* rectified liniar unit (rectifier) \n",
    "* defined as maximum between zero and x - $y = max(0,x)$\n",
    "* more effective than sigmoid and tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2914851",
   "metadata": {},
   "source": [
    "$Softplus$\n",
    "\n",
    "* $y = log(1 + e ^ x)$\n",
    "* is smooth aprox of the rectified liniar unit \n",
    "* it behaves similarly to the ReLU -  for very large and very large negative values of x - smooth transition near 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ddb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x): \n",
    "    return np.loglp(np.exp(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
